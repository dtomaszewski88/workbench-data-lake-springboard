# MayStreet Analytics Workbench Data Lake Springboard

## Welcome

Welcome to the Data Lake Springboard

This Springboard provides a full set of example queries that can run inside Analytics Workbench and retrieve data
from our Data Lake platform.

MayStreet provides multiple JupyterLab notebooks full of example queries you may open and run inside Analytics Workbench; please
consult the rest of this document for a brief introduction to each notebook.

Feel free to copy the code from our notebooks into your own notebook, or play around with the existing notebook.
This is a completely isolated copy which will stay in your own secured Workbench file system, so you're more than
welcome to tinker with it as much as you'd like!

If you'd like to make a copy of the notebook with a different name, select `File` -> `Save As...` to save the notebook
with a new name.

## Notebooks

### _[data-lake-introduction.ipynb](data-lake-introduction.ipynb)_

This notebook will provide a very simple query that can be run to retrieve data from our Data Lake and show it
inside the notebook output.

To run this notebook, simply open it, and click the "Run All" button in the top toolbar.

### _[visualising-data-lake-output.ipynb](visualising-data-lake-output.ipynb)_

This notebook will retrieve AAPL data grouped by feed for the 07th January 2022, and display the output on a very
simple 2D graph.

To run this notebook, simply open it, and click the "Run All" button in the top toolbar.

### _[distributed-data-lake-queries-to-graph.ipynb](distributed-data-lake-queries-to-graph.ipynb)_

This complicated notebook will invoke Data Lake queries throughout a distributed Dask cluster, and will then
collect the response and create an example 3D graph.

You will need to create a Dask cluster before you can run this sample; to do so, please follow the short video
here:
![images/provisioning-cluster.gif](/images/provisioning-cluster.gif)

Once the Dask cluster has moved to the provisioning state, update the address of the cluster inside the notebook;
change the following line:

`cluster_client = Client("tcp://10.0.0.44:8786")`

to

`cluster_client = Client("tcp://<<ip address and port shown inside the Clusters sidebar>>")`

Once you have updated the client to point to the correct Dask cluster, click the "Run All" button in the top toolbar
to run each of the cells in turn.

### _[price-correlation.ipynb](price-correlation.ipynb)_

This notebook fetches the average price of AAPL and TSLA on a given day, calculates the correlation matrix and plots a chart showing the correlation on that day.

To run this notebook, simply open it, and click the "Run All" button in the top toolbar.

### _[multidimensional-chart.ipynb](multidimensional-chart.ipynb)_

This notebook fetches all AAPL trades on a given day, and plots each trade time, quantity and price on a 3d chart.

To run this notebook, simply open it, and click the "Run All" button in the top toolbar.

### _[hourly-price-band.ipynb](hourly-price-band.ipynb)_

This notebook creates a chart of the min and max prices of AAPL trades for each hour on a given day.

To run this notebook, simply open it, and click the "Run All" button in the top toolbar.

## Scripts

### _[custom-export.py](custom-export.py)_

This Python script is an example of a job that can be run daily. It fetches the price and timestamp of each trade of AAPL, IBM, TSLA and F of the previous day, sorted by timestamp.
For each day and each product, it generates a CSV file with the data.
It can run either in a Dask cluster as a scheduled job, or it can be launched from directly inside the Workbench.

Note that the files will be empty if the market was closed the previous day.

## Support

For support, please email <support@maystreet.com>. Thank you.
